import { MentraClient } from '../MentraClient';
import { AccountService } from '../services/AccountService';
import { resolve } from 'path';
import * as fs from 'fs';

const APP_PACKAGE_NAME = 'isaiah.augmentos.livecaptions';

async function main() {
  const server = process.env.SERVER_URL || 'https://isaiah.augmentos.cloud';
  const wsServer = server.replace(/^http/, 'ws');
  const email = process.env.TEST_EMAIL || 'user@example.com';
  const token = process.env.CORE_TOKEN || AccountService.generateTestAccount(email).coreToken;

  console.log('üéØ End-to-End LiveKit Audio Test');
  console.log('================================');
  console.log('Server:', server);
  console.log('Email:', email);
  console.log();

  const client = new MentraClient({
    email,
    serverUrl: `${wsServer}`,
    coreToken: token,
    behavior: { 
      disableStatusUpdates: true,
      useLiveKitAudio: true  // Enable LiveKit audio transport
    },
    debug: { logLevel: 'info', logWebSocketMessages: false },
  });

  let transcriptionReceived = false;

  client.on('connection_ack', (data) => {
    console.log('‚úÖ CONNECTION_ACK received');
    if (data.livekit) {
      console.log('   LiveKit URL:', data.livekit.url);
      console.log('   Room:', data.livekit.roomName);
    }
  });

  client.on('livekit_connected', () => {
    console.log('‚úÖ LiveKit connected to Go bridge');
  });

  // Listen for transcription events
  client.on('display_event', (event) => {
    console.log('üìù DISPLAY_EVENT received', event);
    if (event.packageName === APP_PACKAGE_NAME) {
      const text = event.layout.topText || event.layout.bottomText || event.layout.text ||'';
      if (text && text.trim()) {
        console.log('üìù TRANSCRIPTION:', text);
        transcriptionReceived = true;
      }
    }
  });

  client.on('error', (error) => {
    console.error('‚ùå Error:', error);
  });

  // Connect to server
  console.log('1Ô∏è‚É£  Connecting to server...');
  await client.connect();

  // Wait for LiveKit
  console.log('2Ô∏è‚É£  Waiting for LiveKit connection...');
  // Give bridge + room some time to fully establish
  await new Promise(resolve => setTimeout(resolve, 3000));

  // Install and start transcription app
  console.log('3Ô∏è‚É£  Setting up Live Captions app...');
  try { 
    await client.installApp(APP_PACKAGE_NAME); 
    console.log('   App installed');
  } catch (e) {
    console.log('   App already installed');
  }
  
  try { 
    await client.stopApp(APP_PACKAGE_NAME);
  } catch {}
  
  await client.startApp(APP_PACKAGE_NAME);
  console.log('   ‚úÖ App started');

  // Send audio file with VAD signaling (lets cloud authorize and process speech)
  console.log('4Ô∏è‚É£  Sending audio file via LiveKit bridge...');
  const wavPath = resolve(__dirname, '../audio/short-test-16khz.wav');

  if (!fs.existsSync(wavPath)) {
    console.error('‚ùå Audio file not found:', wavPath);
    process.exit(1);
  }

  // Stream via client helper which sets VAD on/off and streams at proper cadence
  // Stream file (client should route to Go bridge when useLiveKitAudio=true)
  await client.startSpeakingFromFile(wavPath, true);
  console.log('   ‚úÖ Audio streaming triggered');

  // Wait for transcriptions
  console.log('5Ô∏è‚É£  Waiting up to 60s for transcriptions...');
  // Keep the session active for a minute to allow server to process and apps to emit events
  const deadline = Date.now() + 60_000;
  while (Date.now() < deadline) {
    if (transcriptionReceived) break;
    await new Promise(resolve => setTimeout(resolve, 1000));
  }

  // Results
  console.log();
  console.log('üìä Results');
  console.log('==========');
  if (transcriptionReceived) {
    console.log('‚úÖ Transcription received successfully!');
    console.log('‚úÖ End-to-end LiveKit audio flow is working!');
  } else {
    console.log('‚ö†Ô∏è  No transcriptions received');
    console.log('   This could mean:');
    console.log('   - The transcription service is not running');
    console.log('   - Audio is not flowing through LiveKit properly');
    console.log('   - The app is not subscribed to audio events');
  }

  // Keep connection briefly to flush any final events, then disconnect
  await new Promise(resolve => setTimeout(resolve, 1000));
  await client.disconnect();
  process.exit(transcriptionReceived ? 0 : 1);
}

main().catch((err) => {
  console.error('Test failed:', err);
  process.exit(1);
});